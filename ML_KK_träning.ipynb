{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Först delar vi upp datan i träning och test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Normalisera pixelvärdena (skala till intervall [0, 1]) vilket gör att alla egenskaper får samma vikt, vilket vissa modeller är känslig för.\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0\n",
    "\n",
    "#Eftersom vi har träningsdatan på 56000, vill jag snabba upp finjustering av hyperparameter genom att dela upp denna data i hälften de första två omgångarna för finjustering.\n",
    "X_train_partial, X_part, y_train_partial, y_part = train_test_split(X_train_normalized, y_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Börjar med att först göra test på hälften av träningsdatan\n",
    "\n",
    "RFC 10, 50, 100 på n__estimators, none, 10 och 20 på max depth.\n",
    "Den fick 100 och none som bäst hyperparametrar. Blev ett score påÄndrar dem till 80, 100, 120 i omgång två. Ändrar depth till 30, 50, 80.\n",
    "\n",
    "ETC 100, 200, 500 n_estimators, max depth none, 10 och 20, min samples split 2, 5 och 10, min samples leaf 1, 2 och 4.\n",
    "Bästa parametrar: {'ETC__max_depth': None, 'ETC__min_samples_leaf': 1, 'ETC__min_samples_split': 2, 'ETC__n_estimators': 500}\n",
    "KNN neighbors 3, 5 och 7, weights uniform och distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultat första omgång med halva träningsset med följande hyperparametrar\n",
    "'RFC': (RandomForestClassifier(random_state=42), {\n",
    "        'RFC__n_estimators': [10, 50, 100],\n",
    "        'RFC__max_depth': [10, 20, 50]\n",
    "    })\n",
    "    ,'ETC': (ExtraTreesClassifier(random_state=42, bootstrap=True), {\n",
    "        'ETC__n_estimators': [100, 200, 500],\n",
    "        'ETC__max_depth': [10, 20, 50],\n",
    "        'ETC__min_samples_split': [2, 5, 10],\n",
    "        'ETC__min_samples_leaf': [1, 2, 4]\n",
    "    })\n",
    "    ,'KNN': (KNeighborsClassifier(), {'KNN__n_neighbors': [3, 5, 7], 'KNN__weights': ['uniform', 'distance']}) Jag kommer inte ändra KNN för hela träningsset.\n",
    "\n",
    "\n",
    "    Utför GridSearchCV för RFC...\n",
    "För bästa RFC modell: \n",
    "Bästa parametrar: {'RFC__max_depth': 20, 'RFC__n_estimators': 100}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9584\n",
    "Utför GridSearchCV för ETC...\n",
    "För bästa ETC modell: \n",
    "Bästa parametrar: {'ETC__max_depth': 50, 'ETC__min_samples_leaf': 1, 'ETC__min_samples_split': 2, 'ETC__n_estimators': 500}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9608\n",
    "Utför GridSearchCV för KNN...\n",
    "För bästa KNN modell: \n",
    "Bästa parametrar: {'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9600\n",
    "\n",
    "Bästa modellen är: Pipeline(steps=[('ETC',\n",
    "                 ExtraTreesClassifier(bootstrap=True, max_depth=50,\n",
    "                                      n_estimators=500, random_state=42))])\n",
    "Bästa träningsnoggrannhet: 0.9608\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andra omgången med halva träningsdatan och följande hyperparametrar\n",
    "'RFC': (RandomForestClassifier(random_state=42), {\n",
    "        'RFC__n_estimators': [80, 100, 120],\n",
    "        'RFC__max_depth': [15, 20, 30]\n",
    "    })\n",
    "    ,'ETC': (ExtraTreesClassifier(random_state=42, bootstrap=True), {\n",
    "        'ETC__n_estimators': [500, 600],\n",
    "        'ETC__max_depth': [50, 75, 100],\n",
    "        'ETC__min_samples_split': [2],\n",
    "        'ETC__min_samples_leaf': [1]\n",
    "    })\n",
    "    ,'KNN': (KNeighborsClassifier(), {'KNN__n_neighbors': [3, 5, 7, 10], 'KNN__weights': ['uniform', 'distance']})\n",
    "Utför GridSearchCV för RFC...\n",
    "För bästa RFC modell: \n",
    "Bästa parametrar: {'RFC__max_depth': 30, 'RFC__n_estimators': 120}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9589\n",
    "Utför GridSearchCV för ETC...\n",
    "För bästa ETC modell: \n",
    "Bästa parametrar: {'ETC__max_depth': 50, 'ETC__min_samples_leaf': 1, 'ETC__min_samples_split': 2, 'ETC__n_estimators': 500}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9608\n",
    "Utför GridSearchCV för KNN...\n",
    "För bästa KNN modell: \n",
    "Bästa parametrar: {'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}\n",
    "Träningsnoggrannhet med bästa parametrar: 0.9600\n",
    "\n",
    "Bästa modellen är: Pipeline(steps=[('ETC',\n",
    "                 ExtraTreesClassifier(bootstrap=True, max_depth=50,\n",
    "                                      n_estimators=500, random_state=42))])\n",
    "Bästa träningsnoggrannhet: 0.9608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en dictionary med modellerna vi vill använda.\n",
    "models = {\n",
    "   'RFC': (RandomForestClassifier(random_state=42), {\n",
    "        'RFC__n_estimators': [500],\n",
    "        'RFC__max_depth': [15],\n",
    "        'RFC__min_samples_split': [10],\n",
    "        'RFC__min_samples_leaf': [5]\n",
    "    }),\n",
    "    'ETC': (ExtraTreesClassifier(random_state=42, bootstrap=True), {\n",
    "        'ETC__n_estimators': [500],\n",
    "        'ETC__max_depth': [15],\n",
    "        'ETC__min_samples_split': [10],\n",
    "        'ETC__min_samples_leaf': [5]\n",
    "    }),\n",
    "    'KNN': (KNeighborsClassifier(), {'KNN__n_neighbors': [5, 14, 25], 'KNN__weights': ['uniform', 'distance']})\n",
    "}\n",
    "\n",
    "# Vi initierar best_accuracy och best_model där vi kommer spara uppdatera i vår for loop.\n",
    "best_accuracy = 0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utför GridSearchCV för RFC...\n",
      "För bästa RFC modell: \n",
      "Bästa parametrar: {'RFC__max_depth': 15, 'RFC__min_samples_leaf': 5, 'RFC__min_samples_split': 10, 'RFC__n_estimators': 500}\n",
      "Träningsnoggrannhet med bästa parametrar: 0.9605\n",
      "Utför GridSearchCV för ETC...\n",
      "För bästa ETC modell: \n",
      "Bästa parametrar: {'ETC__max_depth': 15, 'ETC__min_samples_leaf': 5, 'ETC__min_samples_split': 10, 'ETC__n_estimators': 500}\n",
      "Träningsnoggrannhet med bästa parametrar: 0.9557\n",
      "Utför GridSearchCV för KNN...\n",
      "För bästa KNN modell: \n",
      "Bästa parametrar: {'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}\n",
      "Träningsnoggrannhet med bästa parametrar: 0.9701\n",
      "\n",
      "Bästa modellen är: Pipeline(steps=[('KNN', KNeighborsClassifier(weights='distance'))])\n",
      "Bästa träningsnoggrannhet: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# Kör GridSearchCV för varje modell och alla hyperparametrar vi initierat i vår models dictionary.\n",
    "for model_name, (model, params) in models.items():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (model_name, model) \n",
    "    ]) # Bygger en pipeline för modellerna\n",
    "    \n",
    "    # GridsearchCV delen, där vi kör hyperparameteroptimering med 5 folds och använder alla processorkärnor för att maximera resurs för träning och minska tid.\n",
    "    print(f\"Utför GridSearchCV för {model_name}...\")\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_normalized, y_train)  # Vi fittar på den normaliserad datan, här har vi vid tidigare träningar haft den partiella.\n",
    "    \n",
    "    #Här lägger vi den bästa modelen med parametrar och score.\n",
    "    best_model_for_this = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    print(f\"För bästa {model_name} modell: \\nBästa parametrar: {best_params}\")\n",
    "    print(f\"Träningsnoggrannhet med bästa parametrar: {best_score:.4f}\")\n",
    "    \n",
    "    # Här ersätts efter varje iteration best_accuracy och best_model med den som har för närvarande bäst\n",
    "    if best_score > best_accuracy:\n",
    "        best_accuracy = best_score\n",
    "        best_model = best_model_for_this\n",
    "    winsound.Beep(2000,500) #Frekvens: 2000 Hz, varaktighet: 500ms för att ge en audio cue när den är klar med en modell\n",
    "winsound.Beep(800,700) #Frekvens: 800 Hz, varaktighet: 700ms för en tydlig audio cue när hela träningen är slut.\n",
    "# Sammanfattning av bästa modellen\n",
    "print(f\"\\nBästa modellen är: {best_model}\")\n",
    "print(f\"Bästa träningsnoggrannhet: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellen har sparats som 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Spara den bästa modellen till en fil\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "print(\"Modellen har sparats som 'best_model.pkl'\")\"\"\"\n",
    "#Har här kommenterat ut koden för att inte råka spara över min sparade modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pystat2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
